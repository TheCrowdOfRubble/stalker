import urllib.parse
import datetime
import logging
import typing
import re

from scrapy.http.response.html import HtmlResponse
from scrapy.linkextractors import LinkExtractor
from scrapy.loader.processors import TakeFirst
from scrapy.utils.datatypes import MergeDict
from w3lib.html import remove_tags


def strip(text: str) -> str:
    return text.strip()


def remove_invisible_character(text: str, loader_context: MergeDict) -> typing.Union[None, str]:
    cleaned_text = text.strip(' \xa0')  # .replace('\xa0', '')
    if not cleaned_text:
        return None
    return cleaned_text


class GetFirstNumber:
    _find_int_pattern = re.compile(r'\d+')

    def __call__(self, text: str, loader_context: MergeDict) -> str:
        number = ''

        matched = self._find_int_pattern.search(text)
        if matched:
            number_string = matched.group()
            number = number_string

        return number


class GetDictFromProfile:
    _PROFILE_FIELD_CN_TO_EN = {
        "æ˜µç§°": "nickname",
        "è®¤è¯": "certification",
        "æ€§åˆ«": "gender",
        "åœ°åŒº": "location",
        "ç”Ÿæ—¥": "birthday",
        "è®¤è¯ä¿¡æ¯": "certification_information",
        "ç®€ä»‹": "introduction",
        "æ€§å–å‘": "sexual_orientation",
        "æ„Ÿæƒ…çŠ¶å†µ": "relationship_status",
        "è¾¾äºº": "weibo_expert",

        "æ‰‹æœºç‰ˆ": "username",  # ä»ã€Œæ‰‹æœºç‰ˆ:https://weibo.cn/yaochenã€ä¸­å–å‡º username
    }

    def __call__(self, text: str, loader_context: MergeDict):
        if not text:
            return None

        pairs = text.split(':', 1)  # ã€Œç®€ä»‹:å·¥ä½œäº‹å®œè¯·è”ç»œç»çºªäººå¼ è•¾ï¼šrunrunlei@126.com ğŸ˜Šã€æœ‰ bugï¼Œæ‰€ä»¥è‹±æ–‡å†’å·æ”¾åœ¨å‰
        if len(pairs) != 2:
            pairs = text.split('ï¼š', 1)  # ä»¥é˜² https: è¢«å‰²å¼€
            if len(pairs) != 2:
                return None

        key_cn, value = pairs
        key_en = self._PROFILE_FIELD_CN_TO_EN.get(key_cn)
        if not key_en:
            return None

        return {key_en: value}


def get_username_from_user_detail_page_url(text: str):
    url_detail: urllib.parse.ParseResult = urllib.parse.urlparse(text)

    if url_detail.netloc != 'weibo.cn' or url_detail.path.startswith('/u/'):
        return None

    url_path_slice = url_detail.path.split('/', 2)
    if len(url_path_slice) < 2:
        logging.error('GET USERNAME FROM URL FAILED: %s', text)
        return None
    return url_path_slice[1]


class WeiboTimeParser:
    _time_delta = datetime.timedelta(days=1)

    _second_pattern = re.compile(r'\d+(?=ç§’å‰)')
    _minute_pattern = re.compile(r'\d+(?=åˆ†é’Ÿå‰)')
    _today_pattern = re.compile(r'ä»Šå¤© (\d+):(\d+)')
    _yesterday_pattern = re.compile(r'æ˜¨å¤© (\d+):(\d+)')
    _year_pattern = re.compile(r'(\d+)æœˆ(\d+)æ—¥ (\d+):(\d+)')
    _full_pattern = re.compile(r'(\d{4})-(\d{2})-(\d{2}) (\d{2}):(\d{2}):(\d{2})')

    @staticmethod
    def _get_today():
        return datetime.date.today().strftime("%Y-%m-%d %%s:%%s:00")

    def _get_yesterday(self):
        return (datetime.date.today() - self._time_delta).strftime("%Y-%m-%d %%s:%%s:00")

    @staticmethod
    def _get_this_year():
        return datetime.date.today().strftime("%Y-%%s-%%s %%s:%%s:00")

    # ä¸è¦å¼„æˆ static çš„ï¼Œå¿…é¡»å’Œå…¶ä»–å‡½æ•°åŒå½¢ï¼
    def _get_time_from_second_pattern(self, matched):
        now = datetime.datetime.now()

        second = int(matched.group(0))
        delta = datetime.timedelta(seconds=second)
        return (now - delta).strftime("%Y-%m-%d %H:%M:%S")

    def _get_time_from_minute_pattern(self, matched):
        now = datetime.datetime.now()

        minute = int(matched.group(0))
        delta = datetime.timedelta(minutes=minute)
        return (now - delta).strftime("%Y-%m-%d %H:%M:%S")

    def _get_time_from_today_pattern(self, matched):
        return self._get_today() % (matched.group(1), matched.group(2))

    def _get_time_from_yesterday_pattern(self, matched):
        return self._get_yesterday() % (matched.group(1), matched.group(2))

    def _get_time_from_year_pattern(self, matched):
        return self._get_this_year() % (matched.group(1), matched.group(2), matched.group(3), matched.group(4))

    def _get_time_from_full_pattern(self, matched):
        return "%s-%s-%s %s:%s:%s" % (
            matched.group(1), matched.group(2), matched.group(3), matched.group(4), matched.group(5), matched.group(6))

    _patterns = {
        _second_pattern: _get_time_from_second_pattern,
        _minute_pattern: _get_time_from_minute_pattern,
        _today_pattern: _get_time_from_today_pattern,
        _yesterday_pattern: _get_time_from_yesterday_pattern,
        _year_pattern: _get_time_from_year_pattern,
        _full_pattern: _get_time_from_full_pattern,
    }

    def __call__(self, raw_datetime_string):
        for pattern in self._patterns:
            matched = pattern.match(raw_datetime_string)
            if matched:
                return self._patterns[pattern](self, matched)

        logging.error("WRONG WEIBO DATE %s", raw_datetime_string)
        return "0000-00-00 00:00:00"


class WeiboContentParser:
    @staticmethod
    def _get_content_from_repost_weibo(text: str) -> str:
        text_slice = text.split('\xa0', 1)  # å½“æŸæ¡å¾®åšååˆ†å¹²å‡€ï¼Œå³æ— ç»„å›¾ã€æ— å…¨æ–‡ã€æ— å¯Œåª’ä½“æ—¶ï¼Œå°±ä¼šæ—  \xa0
        return text_slice[0]

    @staticmethod
    def _remove_repost_reason(text: str) -> str:
        return text[5:]

    @staticmethod
    def _remove_pinned_weibo(text: str) -> str:
        if not text.startswith('<div>[<span class="kt">ç½®é¡¶</span>]'):
            return text
        return text[33:]

    def __call__(self, weibo_loader) -> str:
        weibo_id: str = weibo_loader.get_output_value('weibo_id')
        origin_weibo_id: str = weibo_loader.get_output_value('origin_weibo_id')

        if not origin_weibo_id or weibo_id == origin_weibo_id:  # åŸåˆ›å¾®åš
            content = weibo_loader.get_xpath(
                './div[1]',
                TakeFirst(), self._remove_pinned_weibo, remove_tags, self._get_content_from_repost_weibo, strip
            )
        else:  # è½¬å‘å¾®åš
            content = weibo_loader.get_xpath(
                './div[last()]',
                TakeFirst(), remove_tags, self._get_content_from_repost_weibo, self._remove_repost_reason
            )

        return content


class EmptyTo:
    def __init__(self, target=0):
        self.target = target

    def __call__(self, value, loader_context=None):
        if value:
            return value
        return self.target


class TagsExtractor:
    tags_extractor = LinkExtractor(allow=r'https://m.weibo.cn/search.+q%3D%23.+%23')

    def __call__(self, text):
        response = HtmlResponse(url="", encoding='utf-8', body=text)
        links = self.tags_extractor.extract_links(response)
        return list(map(lambda tag: tag.text[1:-1], links))


# functions
get_first_number = GetFirstNumber()
tags_extractor = TagsExtractor()
get_dict_from_profile = GetDictFromProfile()
get_weibo_content = WeiboContentParser()
parse_weibo_time = WeiboTimeParser()
